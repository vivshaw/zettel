- [How Figma scaled their Postgres](https://www.figma.com/blog/how-figmas-databases-team-lived-to-tell-the-scale/) #db #scalability
- Gordon Hull with some interesting takes on how *autonomous*  autonomous vehicles really are, how effective human supervision can really be, and what that means about ethical culpability: [1](https://www.newappsblog.com/2024/03/drivers-and-ai-and-responsibility-part-1.html), [2](https://www.newappsblog.com/2024/04/drivers-and-ai-and-responsibility-part-2.html) #ml #[[autonomous vehicles]] #ethics
- patio11 on [the anatomy of credit card reward programs](https://www.bitsaboutmoney.com/archive/anatomy-of-credit-card-rewards-programs/) #banking #cards #economics
- Noah Smith on [the perverse incentives of euthanasia](https://www.noahpinion.blog/p/the-perverse-incentives-of-euthanasia) #ethics #dying #economics
- Hazel Weakly on [defining observability](https://hazelweakly.me/blog/redefining-observability/) #observability #sre #[[control theory]] #[[cognitive systems engineering]]
	- > Here we are with complex sociotechnical systems encompassing essentially “every fucking thing a business does to business business” and we have this awesome concept of “we need to understand what we’re doing” and what did we do?
	  We completely and utterly fucked it up by defining observability to mean “gigachad-scale JSON logs parser with a fancy search engine.” Really? Really? That’s the “we solve Real Serious Business Problems™” strategy we went with?
	  It just feels so tragic; what a waste of potential for building avenues of cross-functional understanding and communication.
	- and [Fred Hebert with some followup](https://ferd.ca/a-commentary-on-defining-observability.html)!